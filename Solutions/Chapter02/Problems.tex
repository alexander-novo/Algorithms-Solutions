%!TEX root = ../../Algorithms.tex
\documentclass[Chapter02]{subfiles}

\begin{document}
	\subsection*{Problems}
	\addcontentsline{toc}{subsection}{Problems}

	\begin{problems}
		% 2-1
		\item \textbf{\textit{Insertion sort on small arrays in merge sort.}} Although merge sort runs in $\Theta(n \lg(n))$ worst-case time and insertion sort runs in $\Theta(n^2)$ worst-case time, the constant factors in insertion sort can make it faster in practice for small problem sizes on many machines. Thus, it would make sense to \textbf{\textit{coarsen}} the leaves of recursion by using insertion sort within merge sort when subproblems become sufficiently small. Consider a modification to merge sort in which $n / k$ sublists of length $k$ are sorted using insertion sort and then merged using the standard merging mechanism, where $k$ is a value to be determined.
		\begin{problems}
			% a.
			\item Show that insertion sort can sort the $n / k$ sublists, each of length $k$, in $\Theta(nk)$ worst-case time.
			\begin{answer}
				Since each sublist is of size $k$, we know sorting each sublist will take $\Theta(k^2)$ worst-case time. Since there are $\frac{n}{k}$ such sublists, the total worst-case sorting time will be $\frac{n}{k} \Theta(k^2) = \Theta(nk)$.
			\end{answer}

			% b.
			\item Show how to merge the sublists in $\Theta(n \lg(n / k))$ worst-case time.
			\begin{answer}
				Following our original analysis of \textsc{Merge-Sort}, we know that the $\lg(n)$ factor comes from the height of the recursion tree. Starting from the bottom of the tree, we cut the number of un-merged arrays (represented by the number of nodes on each level, starting with the leaves) in half by merging them. In the worst-case scenario, the recursion tree is complete, so the number of leaves is a power of 2, and the number of times we can cut a number of nodes $n$ in half is $\lg(n)$. So if we start with $n / k$ un-merged arrays (leaves), the number of times we can cut the number of un-merged arrays in half is $\lg(n / k)$. Therefore, we can merge the sublists in $\Theta(n \lg(n / k))$ worst-case time.
			\end{answer}
			
			% c.
			\item Given that the modified algorithm runs in $\Theta(nk + n\lg(n / k))$ worst-case times, what is the largest value of $k$ as a function of $n$ for which the modified algorithm has the same running time as standard merge sort, in terms of $\Theta$-notation?
			\begin{answer}
				If we choose $k = \Theta(\lg(n))$, then the run time is $\Theta(n\lg(n) + n \lg(n / \lg(n)) = \Theta(n\lg(n))$, since $n / \lg(n) < n$ for $n > 2$. If we choose $k$ any (asymptotically) larger, then our runtime would be worse.
			\end{answer}
			
			% d.
			\item How should we choose $k$ in practice?
			\begin{answer}
				In practice, we shouldn't choose $k$ to be an asymptotic function of $n$, since we are arguing that that \textsc{Insertion-Sort} is better than \textsc{Merge-Sort} for \emph{small} values of $k$, based on the constants which are hidden by the asymptotic notation. In practice, we should pick a constant number for $k$ such that the constants of \textsc{Insertion-Sort} allow better run-time than the constants of \textsc{Merge-Sort}. This can be figured out with a more in-depth analysis of the two algorithms, without asymptotic notation, or through trial-and-error on an actual machine.
			\end{answer}
			
		\end{problems}

		% 2-2
		\item \textbf{\textit{Correctness of bubblesort.}} Bubblesort is a popular, but inefficient, sorting algorithm. It works by repeatedly swapping adjacent elements that are out of order.

		\begin{algorithm}[H]
			\SetKwProg{Fn}{def}{\string:}{end}
			\SetKwFunction{FSort}{Bubblesort}
			\SetKwFunction{FSwap}{Swap}

			\Fn{\FSort{$A[1 \dots n]$}}{
				\For{$i \leftarrow 1\ \KwTo\ n - 1$}{
					\For{$j \leftarrow n\ \KwTo\ i + 1$}{
						\If{$A[j] < A[j - 1]$}{
							\FSwap{$A[j], A[j - 1]$}\;
						}
					}
				}
			}
		\end{algorithm}
		\begin{problems}
			% a.
			\item Let $A'$ denote the output of \textsc{Bubblesort($A$)}. To prove that \textsc{Bubblesort} is correct, we need to prove that it terminates and that
			\begin{equation}
				A'[1] \leq A'[2] \leq \dots \leq A'[n], \label[inequality]{eq:ch02-bubble-inequality}
			\end{equation}
			where $n$ is the length of $A$. In order to show that \textsc{Bubblesort} actually sorts, what else do we need to prove?
			\begin{answer}
				We need to prove that $A'$ is a permutation of $A$.
			\end{answer}
		\end{problems}

		The next two parts will prove \cref{eq:ch02-bubble-inequality}.

		\begin{problems}[resume]
			% b.
			\item State precisely a loop invariant for the \textbf{for} loop in lines 3-7, and prove that this loop invariant holds. Your proof should use the structure of the loop invariant proof presented in this chapter. \label{exer:ch02-bubble-part-b}
			\begin{answer}
				We use the following loop invariant:
				\begin{addmargin}[2em]{2em}
					At the start of each iteration of the \textbf{for} loop of lines 3-7, the element $A[j] \leq A[m]$ for all $j + 1 \leq m \leq n$.
				\end{addmargin}

				We then prove this loop invariant using the structure presented in this chapter:
				\begin{description}
					\item[Initialization:] This is trivially true, since $j + 1 = n + 1$, so there is no such $m$.

					\item[Maintenance:] We have two cases:
					\begin{description}
						\item[Case 1:] $A[j - 1] > A[j]$. Then we swap elements, and we know now that $A[j - 1] < A[j]$. So $A[j - 1] < A[m]$ for $j \leq m \leq n$.
						\item[Case 2:] $A[j - 1] \leq A[j]$. Then $A[j - 1] \leq A[j] \leq A[m]$ for all $j \leq m \leq n$.
					\end{description}

					\item[Termination:] Since the loop terminates when $j = i$, then $A[i] \leq A[m]$ for all $i + 1 \leq m \leq n$. In other words, $A[i]$ is the minimum element of the sub-array $A[i \dots n]$.
				\end{description}
			\end{answer}
			
			% c.
			\item Using the termination condition of the loop invariant proved in \cref{exer:ch02-bubble-part-b}, state a loop invariant for the \textbf{for} loop in lines 1-8 that will allows you to prove \cref{eq:ch02-bubble-inequality}. Your proof should use the structure of the loop invariant proof presented in this chapter.
			\begin{answer}
				We use the following loop invariant:
				\begin{addmargin}[2em]{2em}
					At the start of each iteration of the \textbf{for} loop of lines 2-8,
					\begin{equation}
						A'[1] \leq A'[2] \leq \dots \leq A'[i] \leq A'[m], \label[inequality]{eq:ch02-bubble-invariant-inequality}
					\end{equation}
					for all $i + 1 \leq m \leq n$.
				\end{addmargin}

				We then prove this loop invariant using the structure presented in this chapter:
				\begin{description}
					\item[Initialization:] This is trivially true, since $i = 0$, so \cref{eq:ch02-bubble-invariant-inequality} is empty.

					\item[Maintenance:] From \cref{eq:ch02-bubble-invariant-inequality} above, we have for $m = i + 1$,
					\[
						A'[1] \leq A'[2] \leq \dots \leq A'[i] \leq A'[i + 1],
					\]
					and from the loop invariant in \cref{exer:ch02-bubble-part-b} above, we have $A'[i + 1] \leq A[m]$ for all $i + 2 \leq m \leq n$.

					\item[Termination:] Since the loop terminates when $i = n$, \cref{eq:ch02-bubble-inequality} follows directly from \cref{eq:ch02-bubble-invariant-inequality}.
				\end{description}
			\end{answer}
			
			% d.
			\item What is the worst-case running time of bubblesort? How does it compare to the running time of insertion sort?
			\begin{answer}
				In this version of bubblesort, the worst-case running time occurs every time, since there is no early loop termination, and it is
				\begin{align*}
					\sum_{i = 1}^{n - 1} \sum_{j = i + 1}^{n} \Theta(1) &= \sum_{i = 1}^{n - 1} (n - (i + 1) + 1) \Theta(1)\\
						&= n \sum_{i = 1}^{n - 1} \Theta(1) - \sum_{i = 1}^{n - 1} i\Theta(1)\\
						&= n (n - 1) \Theta(1) - \frac{n(n-1)}{2}\Theta(1)\\
						&= \Theta(n^2) - \Theta(n^2)\\
						&= \boxed{\Theta(n^2)}.
				\end{align*}
				This is the same worst case running time of insertion sort, but insertion sort performs better in the best case.
			\end{answer}
			
		\end{problems}
		
		% 2-3
		\item \textbf{\textit{Correctness of Horner's rule.}} The following code fragment implements Horner's rule for evaluating a polynomial
		\begin{align*}
			P(x) &= \sum_{k = 0}^n a_kx^k\\
				&= a_0 + x(a_1 + x(a_2 + \dots + x(a_{n - 1} + xa_n) \dots)),
		\end{align*}
		given the coefficients $a_0, a_1, \dots, a_n$ and a value for $x$:

		\begin{algorithm}[H]
			$y \leftarrow 0$\;
			\For{$i \leftarrow n\ \KwTo\ 0$}{
				$y \leftarrow a_i + x \cdot y$\;
			}
		\end{algorithm}
		\begin{problems}
			% a.
			\item In terms of $\Theta$-notation, what is the running time of this code fragment for Horner's rule?
			\begin{answer}
				The running time for this code fragment is $\Theta(n)$.
			\end{answer}

			% b.
			\item Write pseudocode to implement the naive polynomial-evaluation algorithm that computes each term of the polynomial from scratch. What is the running time of this algorithm? How does it compare to Horner's rule?
			\begin{answer}
				\hfill\\
				\begin{algorithm}[H]
					\SetKw{KwUpto}{upto}
					$y \leftarrow 0$\;
					\For{$i \leftarrow 0\ \KwTo\ n$}{
						$t \leftarrow a_i$\;
						\For{$j \leftarrow 1\ \KwUpto\ i$}{
							$t \leftarrow t \cdot x$\;
						}
						$y \leftarrow y + t$\;
					}
				\end{algorithm}

				The running time of this algorithm is
				\begin{align*}
					(n + 2) + (n + 1) + \qty(\sum_{i = 0}^n (i + 1)) + \qty(\sum_{i = 0}^n i) + (n + 1) &= 3n + 4 + 2\sum_{i = 0}^n i + \sum_{i = 0}^n 1\\
						&= 3n + 4 + n(n + 1) + n\\
						&= n^2 + 5n + 4\\
						&= \Theta(n^2).
				\end{align*}
			\end{answer}
			
			% c.
			\item Consider the following loop invariant: \label{exer:ch02-polynomial-loop-invariant}
			\begin{addmargin}[2em]{2em}
				At the start of each iteration of the \textbf{for} loop of lines 2-4,
				\[
					y = \sum_{k = 0}^{n - (i + 1)} a_{k + i + 1}x^k.
				\]
			\end{addmargin}
			Interpret a summation with no terms as equaling 0. Following the structure of the loop invariant proof presented in this chapter, use the loop invariant to show that, at termination,
			\[
				y = \sum_{k = 0}^n a_kx^k.
			\]
			\begin{answer}
				We prove the loop invariant by following the structure presented in this chapter:
				\begin{description}
					\item[Initialization:] At the start of the loop, $y = 0$ and $i = n$, so we have
					\begin{align*}
						\sum_{k = 0}^{n - (n + 1)} a_{k + i + 1} x^k &= \sum_{k = 0}^{-1} a_{k + i + 1} x^k\\
							&= 0\\
							&= y.
					\end{align*}

					\item[Maintenance:] The next $y$ is now
					\begin{align*}
						a_i + xy &= a_i + x\qty(\sum_{k = 0}^{n - (i + 1)} a_{k + i + 1}x^k)\\
							&= a_i + \sum_{k = 0}^{n - (i + 1)} a_{k + i + 1}x^{k + 1}\\
							&= a_i + \sum_{k = 1}^{n - i} a_{k + i}x^k\\\\
							&= \sum_{k = 0}^{n - i} a_{k + i}x^k.
					\end{align*}

					\item[Termination:] The loop terminates when $i = -1$, so we have
					\begin{align*}
						y &= \sum_{k = 0}^{n - (-1 + 1)} a_{k + -1 + 1}x^k\\
							&= \sum_{k = 0}^{n} a_kx^k,
					\end{align*}
					which is the correct value of $P(x)$.
				\end{description}
			\end{answer}
			
			% d.
			\item Conclude by arguing that the given code fragment correctly evaluates a polynomial characterized by the coefficients $a_0, a_1, \dots, a_n$.
			\begin{answer}
				See the termination step of \ref{exer:ch02-polynomial-loop-invariant} above.
			\end{answer}
			
		\end{problems}
		
		% 2-4
		\item \textbf{\textit{Inversions.}} Let $A[1 \dots n]$ be an array of $n$ distinct numbers. If $i < j$ and $A[i] > A[j]$, then the pair $(i,j)$ is called an \textbf{\textit{inversion}} of $A$.
		\begin{problems}
			% a.
			\item List the five inversions of the array $\langle 2, 3, 8, 6, 1 \rangle$.
			\begin{answer}
				The five inversion are $(1,5), (2,5), (3,5), (4,5), (3,4)$.
			\end{answer}

			% b.
			\item What array with elements from the set $\mathbb{n} = \{1, 2, \dots, n\}$ has the most inversions? How many does it have?
			\begin{answer}
				The array $A = \langle n, (n - 1), \dots, 2, 1 \rangle$ has the most inversions, since $A[i] > A[j]$ whenever $i < j$. In other words, every element is in an inversion pair with every succeeding element, so the number of inversions is
				\begin{align*}
					\sum_{i = 1}^n (n - i) &= \sum_{i = 1}^n n - \sum_{i = 1}^n i\\
						&= n^2 - \frac{1}{2}n(n + 1)\\
						&= \frac{1}{2}n^2 - \frac{1}{2}n\\
						&= \frac{1}{2}n(n - 1).
				\end{align*}
			\end{answer}
			
			% c.
			\item What is the relationship between the running time of insertion sort and the number of inversions in the input array? Justify your answer.
			\begin{answer}
				The number of inversions in the input array is the number of times the \textbf{while} loop on lines 5-7 repeats, so the running time of insertion sort is $\Theta(n + k)$, where $n$ is the size of the input array and $k$ is the number of inversions. This is due to the loop invariant discussed in the chapter:
				\begin{addmargin}[2em]{2em}
					At the start of each iteration of the \textbf{for} loop of lines 1-8, the subarray $A[1 \dots j-1]$ consists of the elements originally in $A[1 \dots j-1]$, but in sorted order.
				\end{addmargin}

				This loop invariant implies another loop invariant:
				\begin{addmargin}[2em]{2em}
					At the start of each iteration of the \textbf{for} loop of lines 1-8, the subarray $A[1 \dots j]$ consists of the same number of inversions $(i,j)$ for $1 \leq i < j$ as the original array $A$. As well, if $(a,j)$ is an inversion, then $(b,j)$ is an inversion for all $1 \leq a < b < j$. Finally, the number of shifts required to insert $A[j]$ into $A[1 \dots j]$ is equal to the number of inversions $(i,j)$ in the original array $A$.
				\end{addmargin}

				We can skip the initialization and maintenance step of proving this loop invariant if we show that this loop invariant is a consequence of the previous loop invariant, which we do now.
				\begin{proof}
					Whenever we insert an element $A[j]$ into $A[1 \dots j]$, the new index $m \leq j$. Therefore, if $(i,j)$ is an inversion in the original array $A$, then $A[i] < A[j]$ in the original array and now $A[m] < A[j]$ in the new subarray, so $(i,m)$ is an inversion in $A[1 \dots j]$. Since $A[1 \dots j - 1]$ consists of the elements originally in $A[1 \dots j-1]$, then there cannot be any ``new'' inversions. Therefore, the number of inversions $(i, j)$ in $A[1 \dots j]$ is equal to the number in the original array $A$. Since $A[1 \dots j-1]$ is sorted, then $1 \leq a < b < j$ implies that $A[a] \leq A[b]$, so if $(a,j)$ is an inversion, then $A[b] \geq A[a] \geq A[j]$, so $(b, j)$ is also an inversion. Finally, we wish to insert $A[j]$ into the minimum index $a$ such that $(a,j)$ is an inversion (or $j$ otherwise, in which case there are no shifts). Since all elements $A[b]$ where $a < b < j$ are shifted, and these are all of the inversions $(a,j)$, then then the number of shifts required to insert $A[j]$ into $A[1 \dots j]$ is equal to the number of such inversions.
				\end{proof}

				Then, we note the termination step of this new loop invariant:
				\begin{description}
					\item[Termination:] The total number of swaps that have been performed is the sum over the number of inversions $(i,j)$ for $2 \leq j \leq n$, which is the sum of all inversions.
				\end{description}
			\end{answer}
			
			% d.
			\item Give an algorithm that determines the number of inversions in any permutation on $n$ elements in $\Theta(n \lg(n))$ worst-case time. (\emph{Hint:} Modify merge sort.)
			\begin{answer}
				See \cref{alg:ch02-inversion-counter}.

				\begin{algorithm}[H]
					\SetKwProg{Fn}{def}{\string:}{end}
					\SetKwFunction{FPerm}{Count-Inversions}
					\SetKwFunction{FMerge}{Merge-Inversions}
					\SetKw{KwAnd}{and}
					\caption{\textsc{Count-Inversions}, which runs in $\Theta(n \lg(n))$ worst-case time. Uses modified version of \textsc{Merge} from \cref{alg:ch02-Merge}.}
					\label{alg:ch02-inversion-counter}

					\Fn{\FPerm{$A[a \dots b]$}}{
						\If{$a < b$}{
							$m \leftarrow \lfloor (a + b) / 2 \rfloor$\;
							$c \leftarrow \FPerm{$A[a \dots m]$}$\;
							$c \leftarrow \FPerm{$A[m + 1 \dots b]$} + c$\;
							$c \leftarrow \FMerge{$A[a \dots m \dots b]$} + c$\;
							\Return{$c$}\;
						}
						\Return{$0$}\;
					}

					\Fn{\FMerge{$A[a \dots m \dots b]$}}{
						$n_1 \leftarrow m - a + 1$\;
						$n_2 \leftarrow b - m$\;
						\For{$i \leftarrow 1\ \KwTo\ n_1$}{
							$L[i] \leftarrow A[a + i - 1]$\;
						}
						\For{$j \leftarrow 1\ \KwTo\ n_2$}{
							$R[j] \leftarrow A[m + j]$\;
						}
						$i \leftarrow 1$\;
						$j \leftarrow 1$\;
						$k \leftarrow 1$\;
						$c \leftarrow 0$\;
						\While{$i \leq n_1\ \KwAnd\ j \leq n_2$}{
							\eIf{$L[i] \leq R[j]$}{
								$A[k] \leftarrow L[i]$\;
								$i \leftarrow i + 1$\;
							}{
								$A[k] \leftarrow R[j]$\;
								$j \leftarrow j + 1$\;
								\tcc{Whenever we insert an element from the right sub-array before finishing the left sub-array, we resolved a number of inversions equal to the remaining un-inserted elements in the left sub-array.}
								$c \leftarrow c + n_1 - i + 1$\;
							}
							$k \leftarrow k + 1$\;
						}
						\For{$i\ \KwTo\ n_1$}{
							$A[k] \leftarrow L[i]$\;
							$k \leftarrow k + 1$\;
						}
						\For{$j\ \KwTo\ n_2$}{
							$A[k] \leftarrow R[j]$\;
							$k \leftarrow k + 1$\;
						}

						\Return{$c$}\;
					}
				\end{algorithm}
			\end{answer}
			
		\end{problems}
		
	\end{problems}

\end{document}